import requests
import pandas as pd
import numpy as np
import pandas_ta as ta

from datetime import datetime, timedelta
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import xgboost as xgb
import lightgbm as lgb
from catboost import CatBoostClassifier
    
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ .env
# load_dotenv(dotenv_path="infra/.env", override=True)
   
    
def load_and_prepare_data():
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ —Å MOEX (SBER), —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç DataFrame —Å–æ —Å—Ç–æ–ª–±—Ü–∞–º–∏:
    [Open, High, Low, Close, Volume, EMA_15, EMA_75, ADX, DI+, DI-, RSI_14, ATR_14]
    –∏ –∏–Ω–¥–µ–∫—Å–æ–º datetime.
    """
    end_date = datetime.now()
    start_date = end_date - timedelta(days=365)  # –ü–æ—Å–ª–µ–¥–Ω–∏–π –≥–æ–¥
    start_date_str = start_date.strftime('%Y-%m-%d')
    end_date_str = end_date.strftime('%Y-%m-%d')
    start_index = 0
    batch_size = 500
    all_candles_data = []

    while True:
        url = (
            f'http://iss.moex.com/iss/engines/stock/markets/shares/boards/TQBR/'
            f'securities/SBER/candles.json?from={start_date_str}&till={end_date_str}'
            f'&interval=60&start={start_index}'
        )
        
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/110.0.0.0 Safari/537.36"
        }

        response = requests.get(url, headers=headers, timeout=15)
        
        data = response.json()
        candles_data = data['candles']['data']
        if not candles_data:
            break
        all_candles_data.extend(candles_data)
        start_index += batch_size

    df = pd.DataFrame(all_candles_data, columns=data['candles']['columns'])
    df['begin'] = pd.to_datetime(df['begin'])
    df.set_index('begin', inplace=True)
    df.rename(
        columns={'open': 'Open', 'high': 'High', 'low': 'Low',
                 'close': 'Close', 'volume': 'Volume'},
        inplace=True
    )
    df = df[['Open', 'High', 'Low', 'Close', 'Volume']]

    # -- –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã --
    df['EMA_15'] = ta.ema(df['Close'], length=15)
    df['EMA_75'] = ta.ema(df['Close'], length=75)

    adx = ta.adx(df['High'], df['Low'], df['Close'], length=14)
    df['ADX'] = adx['ADX_14']
    df['DI+'] = adx['DMP_14']
    df['DI-'] = adx['DMN_14']
    df['RSI_14'] = ta.rsi(df['Close'], length=14)
    df['ATR_14'] = ta.atr(df['High'], df['Low'], df['Close'], length=14)

    df.dropna(inplace=True)
    return df

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# ========================
# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞
# ========================
df = load_and_prepare_data()

# –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ (–∏–Ω–¥–µ–∫—Å—É)
df.sort_index(inplace=True)

# –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º future_return –Ω–∞ 10 —á–∞—Å–æ–≤ –≤–ø–µ—Ä—ë–¥
df['future_return'] = df['Close'].shift(-14) / df['Close'] - 1
df.dropna(subset=['future_return'], inplace=True)

# –§–æ—Ä–º–∏—Ä—É–µ–º —Ç–∞—Ä–≥–µ—Ç (-1, 0, 1)
df['target'] = 0
df.loc[df['future_return'] >  0.01, 'target'] = 1
df.loc[df['future_return'] < -0.01, 'target'] = -1
df['target'] = df['target'].astype(int)

# –¢.–∫. XGBoost/CatBoost/LGB –∂–¥—É—Ç –∫–ª–∞—Å—Å—ã 0..2:
# -1 ‚Üí 0,  0 ‚Üí 1,  1 ‚Üí 2
mapping_dict = {-1: 0, 0: 1, 1: 2}
df['target_mapped'] = df['target'].map(mapping_dict)

# üìä –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç—Ä–µ–Ω–¥–∞ –∏ —Å–∏–ª—ã —Ä—ã–Ω–∫–∞

# üîπ –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –∏ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–π EMA
df['ema_diff'] = df['EMA_15'] - df['EMA_75']  
# ‚ûù –†–∞–∑–Ω–∏—Ü–∞ –º–µ–∂–¥—É 15-–ø–µ—Ä–∏–æ–¥–Ω–æ–π –∏ 75-–ø–µ—Ä–∏–æ–¥–Ω–æ–π —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–π —Å–∫–æ–ª—å–∑—è—â–µ–π —Å—Ä–µ–¥–Ω–µ–π (EMA).
# ‚ûù –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω–æ–µ, –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–π —Ç—Ä–µ–Ω–¥ –≤—ã—à–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ (–≤–æ–∑–º–æ–∂–Ω—ã–π —Ä–æ—Å—Ç).
# ‚ûù –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω–æ–µ, –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–π —Ç—Ä–µ–Ω–¥ –Ω–∏–∂–µ –¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–≥–æ (–≤–æ–∑–º–æ–∂–Ω–æ–µ –ø–∞–¥–µ–Ω–∏–µ).

# üîπ –§–ª–∞–≥: EMA_15 –≤—ã—à–µ EMA_75 (–±—ã—á–∏–π —Å–∏–≥–Ω–∞–ª)
df['ema_15_gt_ema_75'] = (df['EMA_15'] > df['EMA_75']).astype(int)
# ‚ûù –ï—Å–ª–∏ EMA_15 –≤—ã—à–µ EMA_75, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 1 (—Å–∏–≥–Ω–∞–ª –Ω–∞ –≤–æ–∑–º–æ–∂–Ω–æ–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–æ—Å—Ç–∞).
# ‚ûù –ï—Å–ª–∏ EMA_15 –Ω–∏–∂–µ EMA_75, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º 0 (–≤–æ–∑–º–æ–∂–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥).

# üîπ –§–ª–∞–≥: RSI –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç 70 –≤–≤–µ—Ä—Ö (–ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å)
df["rsi_above_70"] = (df["RSI_14"] > 70).astype(int)
# ‚ûù –ï—Å–ª–∏ RSI –≤—ã—à–µ 70, –∞–∫—Ç–∏–≤ —Å—á–∏—Ç–∞–µ—Ç—Å—è –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω—ã–º ‚Üí –≤–æ–∑–º–æ–∂–µ–Ω –æ—Ç–∫–∞—Ç –≤–Ω–∏–∑.
# ‚ûù –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ —Å–∏–≥–Ω–∞–ª –¥–ª—è —Ñ–∏–∫—Å–∞—Ü–∏–∏ –ø—Ä–∏–±—ã–ª–∏.

# üîπ –§–ª–∞–≥: RSI –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç 80 –≤–≤–µ—Ä—Ö (—Å–∏–ª—å–Ω–∞—è –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å)
df["rsi_above_80"] = (df["RSI_14"] > 80).astype(int)
# ‚ûù –ï—Å–ª–∏ RSI –≤—ã—à–µ 80, –∞–∫—Ç–∏–≤ **—Å–∏–ª—å–Ω–æ** –ø–µ—Ä–µ–∫—É–ø–ª–µ–Ω ‚Üí –≤—ã—Å–æ–∫–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏ –≤–Ω–∏–∑.
# ‚ûù –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ —Å–∏–ª—å–Ω—ã–π —Å–∏–≥–Ω–∞–ª –Ω–∞ —Ñ–∏–∫—Å–∞—Ü–∏—é –ø—Ä–∏–±—ã–ª–∏.

# üîπ –§–ª–∞–≥: RSI –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç 20 –≤–Ω–∏–∑ (–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å)
df['rsi_below_20'] = (df['RSI_14'] < 20).astype(int)
# ‚ûù –ï—Å–ª–∏ RSI –Ω–∏–∂–µ 20, –∞–∫—Ç–∏–≤ **–ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω** ‚Üí –≤–æ–∑–º–æ–∂–µ–Ω –æ—Ç—Å–∫–æ–∫ –≤–≤–µ—Ä—Ö.
# ‚ûù –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ —Å–∏–≥–Ω–∞–ª –¥–ª—è –≤—Ö–æ–¥–∞ –≤ –¥–ª–∏–Ω–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏ (–ø–æ–∫—É–ø–∫—É).

# üîπ –§–ª–∞–≥: RSI –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç 30 –≤–Ω–∏–∑ (—Å–ª–∞–±–∞—è –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å)
df['rsi_below_30'] = (df['RSI_14'] < 30).astype(int)
# ‚ûù –ï—Å–ª–∏ RSI –Ω–∏–∂–µ 30, –∞–∫—Ç–∏–≤ **–Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –∑–æ–Ω–µ –ø–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç–∏**.
# ‚ûù –í–æ–∑–º–æ–∂–µ–Ω —Ä–∞–∑–≤–æ—Ä–æ—Ç –≤–≤–µ—Ä—Ö, –Ω–æ —Å–∏–≥–Ω–∞–ª —Å–ª–∞–±–µ–µ, —á–µ–º –ø—Ä–∏ RSI < 20.

# üìä –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞ —Å –ø–æ–º–æ—â—å—é ADX

# üîπ –§–ª–∞–≥: –°–∏–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥ (ADX > 25)
df["adx_strong_trend"] = (df["ADX"] > 25).astype(int)
# ‚ûù –ï—Å–ª–∏ ADX –≤—ã—à–µ 25, —Ç—Ä–µ–Ω–¥ —Å—á–∏—Ç–∞–µ—Ç—Å—è —Å–∏–ª—å–Ω—ã–º.
# ‚ûù –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ DI+ –∏ DI- –ø–æ–¥—Å–∫–∞–∂—É—Ç –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞.

# üîπ –§–ª–∞–≥: –°–ª–∞–±—ã–π —Ç—Ä–µ–Ω–¥ (ADX < 20) –∏–ª–∏ —Ñ–ª—ç—Ç
df["adx_weak_trend"] = (df["ADX"] < 20).astype(int)
# ‚ûù –ï—Å–ª–∏ ADX –Ω–∏–∂–µ 20, —Ç—Ä–µ–Ω–¥ —Å–ª–∞–±—ã–π –∏–ª–∏ —Ä—ã–Ω–æ–∫ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–æ —Ñ–ª—ç—Ç–µ.
# ‚ûù –í —Ç–∞–∫–∏—Ö —É—Å–ª–æ–≤–∏—è—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Ç—Ä–µ–Ω–¥–∞ (DI+ –∏ DI-) –º–µ–Ω–µ–µ –Ω–∞–¥–µ–∂–Ω—ã.

# üìä –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ DI+ –∏ DI-

# üîπ –§–ª–∞–≥: –í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (DI+ > DI-)
df["di_up_trend"] = (df["DI+"] > df["DI-"]).astype(int)
# ‚ûù –ï—Å–ª–∏ DI+ –≤—ã—à–µ DI-, –∞–∫—Ç–∏–≤ –≤ –≤–æ—Å—Ö–æ–¥—è—â–µ–º —Ç—Ä–µ–Ω–¥–µ.

# üîπ –§–ª–∞–≥: –ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (DI- > DI+)
df["di_down_trend"] = (df["DI-"] > df["DI+"]).astype(int)
# ‚ûù –ï—Å–ª–∏ DI- –≤—ã—à–µ DI+, –∞–∫—Ç–∏–≤ –≤ –Ω–∏—Å—Ö–æ–¥—è—â–µ–º —Ç—Ä–µ–Ω–¥–µ.

# üìä –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–∏–ª—ã —Ç—Ä–µ–Ω–¥–∞

# üîπ –§–ª–∞–≥: –°–∏–ª—å–Ω—ã–π –≤–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (ADX > 25 –∏ DI+ > DI-)
df["strong_up_trend"] = ((df["ADX"] > 25) & (df["DI+"] > df["DI-"])).astype(int)
# ‚ûù –ï—Å–ª–∏ ADX –≤—ã—à–µ 25 –∏ DI+ –≤—ã—à–µ DI-, —Ç—Ä–µ–Ω–¥ —Å–∏–ª—å–Ω—ã–π –∏ –≤–æ—Å—Ö–æ–¥—è—â–∏–π.
# ‚ûù –≠—Ç–æ **–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–π –±—ã—á–∏–π —Å–∏–≥–Ω–∞–ª**.

# üîπ –§–ª–∞–≥: –°–∏–ª—å–Ω—ã–π –Ω–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (ADX > 25 –∏ DI- > DI+)
df["strong_down_trend"] = ((df["ADX"] > 25) & (df["DI-"] > df["DI+"])).astype(int)
# ‚ûù –ï—Å–ª–∏ ADX –≤—ã—à–µ 25 –∏ DI- –≤—ã—à–µ DI+, —Ç—Ä–µ–Ω–¥ —Å–∏–ª—å–Ω—ã–π –∏ –Ω–∏—Å—Ö–æ–¥—è—â–∏–π.
# ‚ûù –≠—Ç–æ **–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–Ω—ã–π –º–µ–¥–≤–µ–∂–∏–π —Å–∏–≥–Ω–∞–ª**.

ohlcv = ['Open', 'High', 'Low', 'Close', 'Volume']
futr_exog_cols = ['EMA_15', 'EMA_75', 'ADX', 'DI+', 'DI-', 'RSI_14', 'ATR_14']
additional_cols = [
    'ema_diff', 'ema_15_gt_ema_75',  # –†–∞–∑–Ω–∏—Ü–∞ EMA –∏ —Ñ–ª–∞–≥ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è
    'rsi_above_70', 'rsi_above_80',  # RSI –≤—ã—à–µ 70 –∏ 80
    'rsi_below_20', 'rsi_below_30',  # RSI –Ω–∏–∂–µ 20 –∏ 30
    'adx_strong_trend', 'adx_weak_trend',  # –°–∏–ª–∞ —Ç—Ä–µ–Ω–¥–∞ –ø–æ ADX
    'di_up_trend', 'di_down_trend',  # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ç—Ä–µ–Ω–¥–∞ –ø–æ DI+ –∏ DI-
    'strong_up_trend', 'strong_down_trend'  # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å–∏–ª—å–Ω–æ–≥–æ —Ç—Ä–µ–Ω–¥–∞
]
features = ohlcv + futr_exog_cols + additional_cols

# ====================================
# 2. –î–µ–ª–µ–Ω–∏–µ –Ω–∞ Train / Val / Test
# ====================================
n = len(df)
train_end = int(n * 0.7)
val_end   = int(n * 0.9)

train_df = df.iloc[:train_end]
val_df   = df.iloc[train_end:val_end]
test_df  = df.iloc[val_end:]

X_train, y_train = train_df[features], train_df['target_mapped']
X_val,   y_val   = val_df[features],   val_df['target_mapped']
X_test,  y_test  = test_df[features],  test_df['target_mapped']

# =============================
# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞ –∫–ª–∞—Å—Å–æ–≤
# =============================
print("Train class distribution (mapped):")
print(y_train.value_counts(normalize=True))

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã—á–∏—Å–ª–∏–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –∫–∞–∫ 1 / (–¥–æ–ª—è –∫–ª–∞—Å—Å–∞) - —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç
# –ï—Å–ª–∏ –∫–ª–∞—Å—Å 0 –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –æ—á–µ–Ω—å —á–∞—Å—Ç–æ, –µ–≥–æ –≤–µ—Å –±—É–¥–µ—Ç –º–µ–Ω—å—à–µ, —á–µ–º —É —Ä–µ–¥–∫–∏—Ö –∫–ª–∞—Å—Å–æ–≤.
class_counts = y_train.value_counts(normalize=True).sort_index()  # —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –∏–Ω–¥–µ–∫—Å—É (0,1,2)
class_weights = [1.0 / freq for freq in class_counts]
print("Computed class_weights:", class_weights)

import pandas as pd
import numpy as np
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from collections import Counter
import mlflow
import mlflow.sklearn

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ MLflow ===
mlflow.set_tracking_uri("http://158.160.134.123:8080")
mlflow.set_experiment("ensemble_latest_5000")

# –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –±—É–¥—É—â–µ–π –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–∏
df["future_return"] = df["Close"].shift(-14) / df["Close"] - 1
df.dropna(subset=["future_return"], inplace=True)

# –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è: {-1, 0, 1}
df["target"] = 0
df.loc[df["future_return"] > 0.01, "target"] = 1
df.loc[df["future_return"] < -0.01, "target"] = -1
df["target_mapped"] = df["target"].map({-1: 0, 0: 1, 1: 2})

# –ü–æ—Å–ª–µ–¥–Ω–∏–µ 5000 –Ω–∞–±–ª—é–¥–µ–Ω–∏–π
df = df.tail(5000).copy()
X = df.drop(columns=["target", "target_mapped", "future_return"])
y = df["target_mapped"]

# === –ú–æ–¥–µ–ª–∏ ===
models = {
    "XGB": XGBClassifier(
        objective="multi:softmax",
        max_depth=3,
        n_estimators=408,
        subsample=0.754,
        colsample_bytree=0.602,
        num_class=3,
        eval_metric="mlogloss",
        random_state=42,
        use_label_encoder=False,
    ),
    "LGBM": LGBMClassifier(
        objective="multiclass",
        max_depth=3,
        n_estimators=928,
        subsample=0.724,
        colsample_bytree=0.658,
        num_class=3,
        random_state=42,
    ),
    "CatBoost": CatBoostClassifier(
        loss_function="MultiClass",
        random_seed=42,
        iterations=1000,
        learning_rate=0.05,
        early_stopping_rounds=100,
        use_best_model=True,
        verbose=0,
    ),
}

selected_models = list(models.keys())

with mlflow.start_run(run_name="last_5000"):
    preds = {}
    for name, model in models.items():
        if name == "CatBoost":
            model.fit(X, y, eval_set=(X, y))
        else:
            model.fit(X, y)

        y_pred = model.predict(X)
        if isinstance(y_pred, np.ndarray) and y_pred.ndim == 2:
            y_pred = np.argmax(y_pred, axis=1)
        preds[name] = y_pred

        # === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ ===
        with mlflow.start_run(run_name=f"{name}_model", nested=True):
            mlflow.log_param("model_type", name)
            mlflow.log_params(model.get_params())
            mlflow.log_metric("accuracy", accuracy_score(y, y_pred))
            mlflow.log_metric("f1_macro", f1_score(y, y_pred, average="macro"))
            mlflow.log_metric("precision_macro", precision_score(y, y_pred, average="macro"))
            mlflow.log_metric("recall_macro", recall_score(y, y_pred, average="macro"))

            # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
            if name == "XGB":
                mlflow.xgboost.log_model(model, artifact_path="model", registered_model_name="XGBoostModel")
            elif name == "LGBM":
                mlflow.lightgbm.log_model(model, artifact_path="model", registered_model_name="LightGBMModel")
            elif name == "CatBoost":
                mlflow.catboost.log_model(model, artifact_path="model", registered_model_name="CatBoostModel")

    # === –ê–Ω—Å–∞–º–±–ª—å ===
    final_preds = []
    for i in range(len(X)):
        votes = [int(preds[name][i]) for name in selected_models]
        vote_count = Counter(votes).most_common()
        if vote_count[0][1] > 1:
            final_preds.append(vote_count[0][0])
        else:
            final_preds.append(np.random.choice([vote_count[0][0], vote_count[1][0]]))

    acc = accuracy_score(y, final_preds)
    f1 = f1_score(y, final_preds, average="macro")
    prec = precision_score(y, final_preds, average="macro")
    rec = recall_score(y, final_preds, average="macro")
    correct_frac = (np.sum((np.array(final_preds) == 0) & (y.values == 0)) +
                    np.sum((np.array(final_preds) == 2) & (y.values == 2))) / len(y)

    mlflow.log_metric("ensemble_accuracy", acc)
    mlflow.log_metric("ensemble_f1_macro", f1)
    mlflow.log_metric("ensemble_precision_macro", prec)
    mlflow.log_metric("ensemble_recall_macro", rec)
    mlflow.log_metric("ensemble_correct_frac_0_2", correct_frac)

    df_preds = pd.DataFrame({
        "index": X.index,
        "true": y.values,
        "ensemble_pred": final_preds
    })
    pred_path = "ensemble_last_5000_predictions.csv"
    df_preds.to_csv(pred_path, index=False)
    mlflow.log_artifact(pred_path, artifact_path="ensemble_preds")

mlflow.end_run()